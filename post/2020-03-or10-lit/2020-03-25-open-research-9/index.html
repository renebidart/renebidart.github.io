<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Rene Bidart">

  
  
  
    
  
  <meta name="description" content="VAE intuition: BETA VAE! https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/ https://arxiv.org/pdf/1706.02262.pdf Tutorial: https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773?casa_token=ikcvwnjzvHQAAAAA%3A0KzUTSM4saUASpVBTfK0nVJxhlh41o5FKFhQkmMAd2uIOxollNkbQEgznDrpZkwEPsVVgDEcPMII Less important: https://arxiv.org/abs/1509.00519
Disentangled (in general) Previous work has shown in general https://arxiv.org/pdf/1811.12359.pdf the unsupervised learning of disentangled representations requires inductive bias on the model and the data.">

  
  <link rel="alternate" hreflang="en-us" href="https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157504369-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-157504369-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu5e15e861ad43a166b29f0ae919c910d4_1675_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu5e15e861ad43a166b29f0ae919c910d4_1675_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/">

  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Academic">
  <meta property="og:url" content="https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/">
  <meta property="og:title" content="Open Research 10: Literature Review | Academic">
  <meta property="og:description" content="VAE intuition: BETA VAE! https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/ https://arxiv.org/pdf/1706.02262.pdf Tutorial: https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773?casa_token=ikcvwnjzvHQAAAAA%3A0KzUTSM4saUASpVBTfK0nVJxhlh41o5FKFhQkmMAd2uIOxollNkbQEgznDrpZkwEPsVVgDEcPMII Less important: https://arxiv.org/abs/1509.00519
Disentangled (in general) Previous work has shown in general https://arxiv.org/pdf/1811.12359.pdf the unsupervised learning of disentangled representations requires inductive bias on the model and the data."><meta property="og:image" content="img/map[gravatar:%!s(bool=false) shape:circle]">
  <meta property="twitter:image" content="img/map[gravatar:%!s(bool=false) shape:circle]"><meta property="og:locale" content="en-us">
  
    
    
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/"
  },
  "headline": "Open Research 10: Literature Review",
  
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Rene Bidart"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Academic",
    "logo": {
      "@type": "ImageObject",
      "url": "https://renebidart.com/images/icon_hu5e15e861ad43a166b29f0ae919c910d4_1675_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "VAE intuition: BETA VAE! https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/ https://arxiv.org/pdf/1706.02262.pdf Tutorial: https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773?casa_token=ikcvwnjzvHQAAAAA%3A0KzUTSM4saUASpVBTfK0nVJxhlh41o5FKFhQkmMAd2uIOxollNkbQEgznDrpZkwEPsVVgDEcPMII Less important: https://arxiv.org/abs/1509.00519\nDisentangled (in general) Previous work has shown in general https://arxiv.org/pdf/1811.12359.pdf the unsupervised learning of disentangled representations requires inductive bias on the model and the data."
}
</script>

  

  


  


  





  <title>Open Research 10: Literature Review | Academic</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Academic</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Academic</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Open Research 10: Literature Review</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Jan 1, 0001
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <h2 id="vae-intuition">VAE intuition:</h2>
<p>BETA VAE!

<a href="https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/" target="_blank" rel="noopener">https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/</a>

<a href="https://arxiv.org/pdf/1706.02262.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1706.02262.pdf</a>
Tutorial:

<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773?casa_token=ikcvwnjzvHQAAAAA%3A0KzUTSM4saUASpVBTfK0nVJxhlh41o5FKFhQkmMAd2uIOxollNkbQEgznDrpZkwEPsVVgDEcPMII" target="_blank" rel="noopener">https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773?casa_token=ikcvwnjzvHQAAAAA%3A0KzUTSM4saUASpVBTfK0nVJxhlh41o5FKFhQkmMAd2uIOxollNkbQEgznDrpZkwEPsVVgDEcPMII</a>
Less important:

<a href="https://arxiv.org/abs/1509.00519" target="_blank" rel="noopener">https://arxiv.org/abs/1509.00519</a></p>
<h2 id="disentangled-in-general">Disentangled (in general)</h2>
<p>Previous work has shown in general 
<a href="https://arxiv.org/pdf/1811.12359.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1811.12359.pdf</a> the unsupervised learning of disentangled representations requires inductive bias on the model and the data. For this work we will focus on a particular .</p>
<p>Following the results in this paper, we are focusing on a specific case of learning a disentangled representation, with a specific goal. In this work we will focus on the aim of disentangling object orientation and shape, with the goal of allowing lower capacity models to generalize better.</p>
<p>There is no formal definition of what it means to be a disentangled representation, but intuitively … In this work we will focus on disentangling the shape of an object and its orientation.</p>
<p>The idea is the model has to &ldquo;learn&rdquo; what the object is at each orientation, rather than representing it as a single object with an orientation.</p>
<h2 id="supervised">Supervised:</h2>
<p>
<a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Worrall_Interpretable_Transformations_With_ICCV_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2017/papers/Worrall_Interpretable_Transformations_With_ICCV_2017_paper.pdf</a>
Given the relative rotation between a set of 2d faces, they use an autoencoder style network to learn a laten representation of the face that can be transformed by the 3d rotation.  This enforces that the latent representation accurately reflects 3d structure of the face, because it is transformed in 3d space.</p>
<h4 id="weakly-supervised">Weakly supervised</h4>
<p>
<a href="https://openreview.net/pdf?id=H1e1XeXlP4" target="_blank" rel="noopener">https://openreview.net/pdf?id=H1e1XeXlP4</a>
Using groups of observations:

<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16521" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16521</a></p>
<h2 id="inverse-graphics-style">INVERSE GRAPHICS Style</h2>
<p>pre-specified decoders:</p>
<ul>
<li>review these again

<a href="http://papers.nips.cc/paper/7297-visual-object-networks-image-generation-with-disentangled-3d-representations.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/7297-visual-object-networks-image-generation-with-disentangled-3d-representations.pdf</a>
They separate image generation into shape, viewpoint and texture by rendering a 3d shape, then rendering a 2.5D (silhouette and depth map), and finally adds texture.</li>
</ul>
<p>Learn a disentangled generative model for images by explicitly specifying the generation in terms of shape, viewpoint, and texture. Use a 3D shape generation network, which is then fed into a renderer to show this in 2D, including viewpoint and texture.
Does not disentangle the 3D pose of the object, ((this would be a good extension of our work, using this to extend it to generating 2d with viewpoint and texture.)) -reread this more closely</p>
<p>
<a href="http://papers.nips.cc/paper/7459-3d-aware-scene-manipulation-via-inverse-graphics.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/7459-3d-aware-scene-manipulation-via-inverse-graphics.pdf</a>
Here they use a multiple encoder networks to generate semantic segmentation, object pose and orientation, and texture parameters from an image. The image is then reconstructed by &hellip;</p>
<p>
<a href="https://arxiv.org/pdf/1906.03281.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1906.03281.pdf</a></p>
<h3 id="half--inverse-graphics-style">Half- INVERSE GRAPHICS Style</h3>
<p>
<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Xing_Unsupervised_Disentangling_of_Appearance_and_Geometry_by_Deformable_Generator_Network_CVPR_2019_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_CVPR_2019/papers/Xing_Unsupervised_Disentangling_of_Appearance_and_Geometry_by_Deformable_Generator_Network_CVPR_2019_paper.pdf</a>
They disentangle appearance and geometry by using different generator for each and combining the results using a warping function to create an image. They also extend this to a VAE, where they use two networks to infer the latent vectors describing appearance and geometry.</p>
<p>
<a href="http://papers.nips.cc/paper/8387-explicit-disentanglement-of-appearance-and-perspective-in-generative-models.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/8387-explicit-disentanglement-of-appearance-and-perspective-in-generative-models.pdf</a>
They extent a VAE to consider two separate latent spaces, a perspective and appearance latent space,
((((Read this for inspiration on paper writing))) Good refs on what counts as disentangled, and good lit review.</p>
<p>
<a href="https://arxiv.org/pdf/1903.06946.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1903.06946.pdf</a>

<a href="https://arxiv.org/pdf/1806.06298.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1806.06298.pdf</a></p>
<h3 id="very-weak-priors-over-latent-space-model-structure">very weak priors over latent space, model structure:</h3>
<p>
<a href="http://papers.nips.cc/paper/7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models.pdf</a></p>
<h3 id="some-metrics-and-methods-important">Some metrics and methods: (important)</h3>
<p>
<a href="https://arxiv.org/pdf/1711.00848.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.00848.pdf</a>

<a href="http://papers.nips.cc/paper/7527-isolating-sources-of-disentanglement-in-variational-autoencoders.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/7527-isolating-sources-of-disentanglement-in-variational-autoencoders.pdf</a></p>
<h3 id="heading">???</h3>
<p>
<a href="https://arxiv.org/abs/1906.11732" target="_blank" rel="noopener">https://arxiv.org/abs/1906.11732</a></p>
<h2 id="equivariance">Equivariance</h2>
<p>
<a href="https://dspace.mit.edu/handle/1721.1/113001" target="_blank" rel="noopener">https://dspace.mit.edu/handle/1721.1/113001</a></p>
<h2 id="important-3d-models">Important 3d models</h2>
<p>
<a href="http://papers.nips.cc/paper/6600-unsupervised-learning-of-3d-structure-from-images.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/6600-unsupervised-learning-of-3d-structure-from-images.pdf</a>

<a href="https://ieeexplore.ieee.org/abstract/document/7469347" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/7469347</a></p>
<h3 id="optimizing-affine-transforms-in-vaes">Optimizing Affine Transforms in VAEs</h3>
<p>Our goal is to create a VAE which will only encode a subset of affine transforms, but generalize to all. This is shown below:
<img src="../avae_3d.png" alt="avae_3d.png"></p>
<p>
<a href="https://renebidart.com/post/or5/2020-03-02-open-research-5/" target="_blank" rel="noopener">Previously</a> we showed takes a higher capacity VAE to encode all possible orientations of an object, compared to encoding a single orientation. Our goal is to create a smaller model by only encoding a subset of all orientations, but still generalize to all orientations at inference. But how can we do this, given a dataset at random orientations?</p>
<p>Because the VAE is a generative model, we can the optimize an affine transform to find the orinetation at which the VAE best encodes the data, or has lowest loss. Our approach is to use an inner optimization loop during training to optimize this affine transform. The goal is that this will force the model to encode only a subset of the distribution. Then at inference time, this affine optimization can be used to allow the model to generalize to all orientations.</p>
<p>Normally stochastic gradient descent is used to update the parameters of the network to reduce the loss of the VAE. Here we will take another approach, where the forward pass of the VAE will include an optimization over a set of parameters, where the parameters are optimized to reduce the VAE&rsquo;s loss, maximizing the ELBO. These are the parameters of an affine transform, so the process corresponds to finding the optimal orientation to encode an object at. This optimization objective is shown as:</p>
<p>$\underset{\alpha}{\text{argmin}}\{ L_{VAE}[\tau_{\alpha}^{-1}(p_\rho(q_\phi(\tau_{\alpha}(x))))]\}$</p>
<p>To train a network of this form is very expensive, because the above optimization must be solved once for each forward pass. As I discussed 
<a href="https://renebidart.com/post/or7/2020-03-17-open-research-7/" target="_blank" rel="noopener">before</a>, optimizing $\alpha$ is differentiable, but is likely to get caught in a local optima. To overcome this, we evaluate the performance at a number of different random initializations of $\alpha$, and then select the top k of these initializations to do gradient descent on. Here we used 32 random initializations, and did gradient descent on the top 8 of these.</p>
<p>These tests take a while to run, so we&rsquo;ll look at results later, and give a rigorous interpretation of the above in terms of variational inference.</p>

    </div>

    







<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/&amp;text=Open%20Research%2010:%20Literature%20Review" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/&amp;t=Open%20Research%2010:%20Literature%20Review" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Open%20Research%2010:%20Literature%20Review&amp;body=https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/&amp;title=Open%20Research%2010:%20Literature%20Review" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Open%20Research%2010:%20Literature%20Review%20https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://renebidart.com/post/2020-03-or10-lit/2020-03-25-open-research-9/&amp;title=Open%20Research%2010:%20Literature%20Review" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  





  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu2b8d075eea2632f115321e025ae11a3e_74778_270x270_fill_q90_lanczos_center.jpg" alt="Rene Bidart">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://renebidart.com">Rene Bidart</a></h5>
      <h6 class="card-subtitle">PhD Candidate</h6>
      <p class="card-text">PhD candidate at University of Waterloo - Deep Learning</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:renebidart@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=8TIUlYkAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/renebidart" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>












  
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js" integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
